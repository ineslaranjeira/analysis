{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from os import getcwd\n",
    "from os.path import join\n",
    "from sys import path\n",
    "path.insert(1, join(getcwd(), '..', '..', 'ibllib', 'python'))\n",
    "import dat\n",
    "from alf import alf_parts, is_alf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from behavior_plots import *\n",
    "from load_behavior import load_behavior\n",
    "#import load_behavior as load_behavior\n",
    "path = r'\\\\zubjects.cortexlab.net\\Subjects'\n",
    "#path = 'G:\\\\'\n",
    "#TODO: Fix ln 51 dat: value error on list of strings\n",
    "#TODO: make_pretty decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Windowed performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function load_behavior at 0x000000000AF0ABF8>\n"
     ]
    }
   ],
   "source": [
    "print(load_behavior.load_behavior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading trials and plotting\n",
    "Below we load all the experiments locally and make three plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-109d315aa336>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrefs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_exps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LEW010'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrootDir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Load all data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mload_behavior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrootDir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mref\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrefs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdfs\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-109d315aa336>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrefs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_exps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LEW010'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrootDir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Load all data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mload_behavior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrootDir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mref\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrefs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdfs\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\analysis\\python\\load_behavior.py\u001b[0m in \u001b[0;36mload_behavior\u001b[1;34m(ref, rootDir)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mrootDir\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mrootDir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrootDir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0malfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mis_alf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mparts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0malf_parts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0malf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0malfs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dat' is not defined"
     ]
    }
   ],
   "source": [
    "refs, date, seq = dat.list_exps('LEW010', rootDir=path)\n",
    "# Load all data\n",
    "dfs = [load_behavior(ref, rootDir=path) for ref in refs]\n",
    "dfs = [df for df in dfs if df is not None]\n",
    "fig = plt.figure()\n",
    "plot_perf_heatmap(dfs, plt.gca())\n",
    "plt.figure()\n",
    "plot_RTs(dfs[-1], plt.gca())\n",
    "plt.figure()\n",
    "plot_psychometric(dfs[-1], plt.gca())\n",
    "plt.figure()\n",
    "make_pretty(plot_windowed_perf(dfs[-1], 20, plt.gca()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive RT plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*[12, 321])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading trials for multiple subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Subject list\n",
    "subjects = ['ALK081', 'LEW008', 'LEW009', 'LEW010']\n",
    "# List all experiments for each subject\n",
    "refs = [dat.list_exps(subject, path)[0] for subject in subjects]\n",
    "# Flatten list\n",
    "#flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "#refs = [flatten(l) for l in refs]\n",
    "# Load trials from ALFs\n",
    "dfs = [[alf.load_behavior(ref, path) for ref in subject] for subject in refs]\n",
    "dfs = [[df for df in subjectDfs if df is not None] for subjectDfs in dfs]\n",
    "refs = [[df.name for df in subjectDfs] for subjectDfs in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wheel, wm = [[load_wheel(ref, path) for ref in subject] for subject in refs]\n",
    "#wheel, wm = [[w for w in subjectW if w is not None] for subjectW in dfs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#TODO: Plot in grid\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plt.clf()\n",
    "grid = plt.GridSpec(3, 3, wspace=.5, hspace=.9)\n",
    "ax1 = plt.subplot(grid[0, 0])\n",
    "ax2 = plt.subplot(grid[0, 1])\n",
    "ax3 = plt.subplot(grid[0, 2])\n",
    "\n",
    "ax4 = plt.subplot(grid[2, :])\n",
    "ax5 = plt.subplot(grid[1, 1])\n",
    "ax6 = plt.subplot(grid[1, 2])\n",
    "ax7 = plt.subplot(grid[1, 0])\n",
    "\n",
    "@interact(Subject=subjects)\n",
    "def subject_plots(Subject):\n",
    "    plot_perf_heatmap(dfs[subjects.index(Subject)], ax1)\n",
    "    ax2.cla()\n",
    "    plot_learning(dfs[subjects.index(Subject)], ax2)\n",
    "    plot_repeats(dfs[subjects.index(Subject)], ax=ax3)\n",
    "    ax3.legend().set_visible(False)\n",
    "    \n",
    "    @interact(Subject=fixed(Subject), Session=(1,len(dfs[subjects.index(Subject)])))\n",
    "    def session_plots(Subject, Session):\n",
    "        df = dfs[subjects.index(Subject)][Session-1]\n",
    "        plot_RTs(df,ax4)\n",
    "        #TODO: return axes for setting title\n",
    "        plot_psychometric(df,ax5)\n",
    "        plot_windowed_perf(df, 20, ax6)\n",
    "        ax4.legend().set_visible(False)\n",
    "        fig.suptitle(df.name)\n",
    "\n",
    "        @interact(update=False)\n",
    "        def update_wheel_plot(update=True):\n",
    "            if update == True:\n",
    "                wheel, wm = load_wheel(df.name, rootDir=path)\n",
    "                if wm is None:\n",
    "                    return\n",
    "                ret, = plot_wheel_at_move_onset((wheel, wm),ax7)\n",
    "                ax7.set_xlim([0, 1000])\n",
    "                for option in ret.keys():\n",
    "                    if option in ['flinch', 'other']:\n",
    "                        plt.setp(ret[option], visible=False)\n",
    "    return Subject\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance over the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning(dfs, ax=None):\n",
    "    \n",
    "    nn = np.array([sum((df['contrast']>=.5) & \n",
    "                       (df['included']==True)) \n",
    "                   for df in dfs])\n",
    "    pp = np.array([sum((df['contrast']>=.5) & \n",
    "                       (df['feedbackType']==1) & \n",
    "                       (df['included']==True))\n",
    "                   for df in dfs]) / nn\n",
    "    ci = 1.96*np.sqrt(pp*(1-pp)/nn)\n",
    "    # graphics\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "    ax.errorbar(np.arange(1,len(dfs)+1), pp, yerr=ci, capsize=2)\n",
    "    ax.plot([1, len(dfs)+1], [.5, .5], 'k:')\n",
    "    # Hide the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    # Reduce the clutter\n",
    "    ax.set_xticks([1] + [i * 5 for i in range(1,round(len(dfs)/5))])\n",
    "    ax.set_yticks([0, .25, .5, .75, 1.])\n",
    "    # Set bounds of axes lines\n",
    "    ax.spines['left'].set_bounds(.4, 1.)\n",
    "    ax.spines['bottom'].set_bounds(1, len(dfs)+1)\n",
    "    # Explode out axes\n",
    "    #ax.spines['left'].set_position(('outward',10))\n",
    "    ax.spines['bottom'].set_position(('outward',10))\n",
    "    # Set the limits\n",
    "    ax.set_xlim([0, len(dfs)+1])\n",
    "    ax.set_ylim([.4, 1.])\n",
    "    plt.xlabel('Session #')\n",
    "    plt.ylabel('Performance at contrast >= 50%')\n",
    "    return ax\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "for i in dfs:\n",
    "    plot_learning(i, ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Mice adopt win-stay lose-switch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro\n",
    "\n",
    "plot_repeats(dfs[1], normalize=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(dfs[0][0]['feedbackType'].where(dfs[0][0]['repNum']>5)==1)\n",
    "print(list(range(1,6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the wheel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, getcwd\n",
    "from os.path import isfile, join\n",
    "from alf import *\n",
    "def load_wheel(ref, rootDir=None):\n",
    "    \"\"\"\n",
    "    Load the wheel object for a given experiment reference\n",
    "    \n",
    "    Example:\n",
    "        df = load_wheel('2018-09-11_1_MOUSE', rootDir = r'\\\\server1\\Subjects')\n",
    "        df.head()\n",
    "        \n",
    "    Args: \n",
    "        subject (str): The subject name\n",
    "        rootDir (str): The root directory, i.e. where the subject data are stored.\n",
    "                       If rootDir is None, the current working directory is used.\n",
    "        \n",
    "    Returns:\n",
    "        wheel (DataFrame): DataFrame constructed from the wheel object of the ALF \n",
    "                           files located in the experiment directory\n",
    "        wm (DataFrame): DataFrame constructed from the wheelMoves object of the  \n",
    "                           ALF files located in the experiment directory\n",
    "\n",
    "    TODO: Deal with namespaces: currently hard-coded\n",
    "    TODO: Make function more efficient: Does everything twice (once per ALF obj)\n",
    "    TODO: Extract first few lines as decorator\n",
    "    \"\"\"\n",
    "    if rootDir is None:\n",
    "        rootDir = getcwd()\n",
    "    path = dat.exp_path(ref, rootDir)\n",
    "    alfs = [f for f in listdir(path) if (isfile(join(path, f))) & (is_alf(f)) & (f.startswith('_ibl_wheel'))]\n",
    "    if not alfs:\n",
    "        print('{}: Nothing to process'.format(ref))\n",
    "        return None, None\n",
    "    # Pull paths of trials ALFs\n",
    "    wheelPos = np.load(join(path, '_ibl_wheel.position.npy')).squeeze()\n",
    "    wheelVel = np.load(join(path, '_ibl_wheel.velocity.npy')).squeeze()\n",
    "    t = np.load(join(path, '_ibl_wheel.timestamps.npy')).squeeze()\n",
    "    times = np.interp(np.arange(0,len(wheelPos)), t[:,0], t[:,1])\n",
    "    wheel = pd.DataFrame({'position':wheelPos, 'velocity':wheelVel, 'times':times})\n",
    "    \n",
    "    intervals = np.load(join(path, '_ibl_wheelMoves.intervals.npy')).squeeze()\n",
    "    try:\n",
    "        movesType = pd.read_csv(join(path, '_ibl_wheelMoves.type.csv'), header=None)\n",
    "        wm = pd.DataFrame({'onset':intervals[:,0], 'offset':intervals[:,1], 'type':movesType.values[0]})\n",
    "    except: #TODO: Deal with missing movesType or empty file\n",
    "        wm = None\n",
    "\n",
    "    return wheel, wm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at wheel moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wheel, wm = load_wheel(refs[1][-2], rootDir=path)\n",
    "#def plot_wheel_at_move_onset()\n",
    "f = plt.figure()\n",
    "ax = f.gca()\n",
    "colours = {'CW':'b', 'CCW':'r', 'flinch':'k', 'other':'k'}\n",
    "ret = {'CW':[], 'CCW':[], 'flinch':[], 'other':[]}\n",
    "for i in range(0,len(wm)):\n",
    "    t = (wheel['times'] > wm['onset'][i]) & (wheel['times'] < wm['offset'][i])\n",
    "    pos = wheel['position'][t]\n",
    "    wheelTimes = wheel['times'][t]\n",
    "    relativeTimes = wheelTimes - wheelTimes.iloc[0]\n",
    "    pos = pos - pos.iloc[0]\n",
    "    ln, = ax.plot(relativeTimes*1000, pos.values, c=colours[wm['type'][i]], label=wm['type'][i])\n",
    "    ret[wm['type'][i]].append(ln)\n",
    "    \n",
    "plt.xlim([0, 10000])\n",
    "plt.ylim([-7, 7])\n",
    "# Hide the right and top spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "# Set bounds of axes lines\n",
    "#ax.spines['left'].set_bounds(0, 1)\n",
    "#ax.spines['bottom'].set_bounds(1, len(dfs)+1)\n",
    "# Explode out axes\n",
    "ax.spines['left'].set_position(('outward',10))\n",
    "ax.spines['bottom'].set_position(('outward',10))\n",
    "plt.title = refs[1][-2];\n",
    "plt.xlabel('Time from movement onset (ms)')\n",
    "plt.ylabel('Relative position (cm)')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "btn = widgets.SelectMultiple(options=ret.keys(), value=['CCW', 'CW'], description='Show:')\n",
    "slider = widgets.IntRangeSlider(\n",
    "    value=[0, 1000],\n",
    "    min=0,\n",
    "    max=10000,\n",
    "    step=1,\n",
    "    description='x limit:',\n",
    "    disabled=False,\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    ")\n",
    "@interact(Selected=btn, lim=slider)\n",
    "def set_visible(Selected, lim):\n",
    "    for option in ret.keys():\n",
    "        if option in Selected:\n",
    "            plt.setp(ret[option], visible=True)\n",
    "            #ax.plot([0, 500], [-6, 4], 'r-')\n",
    "            #[ln.set_visible(True) for ln in ret[option]]\n",
    "        else:\n",
    "            plt.setp(ret[option], visible=False)\n",
    "    ax.set_xlim(lim)\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wheel_at_move_onset(wheelData, ax=None):\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "    ax.cla()\n",
    "    wheel = wheelData[0]\n",
    "    wm = wheelData[1]\n",
    "    colours = {'CW':'b', 'CCW':'r', 'flinch':'k', 'other':'k'}\n",
    "    ret = {'CW':[], 'CCW':[], 'flinch':[], 'other':[]}\n",
    "    for i in range(0,len(wm)):\n",
    "        t = (wheel['times'] > wm['onset'][i]) & (wheel['times'] < wm['offset'][i])\n",
    "        pos = wheel['position'][t]\n",
    "        wheelTimes = wheel['times'][t]\n",
    "        relativeTimes = wheelTimes - wheelTimes.iloc[0]\n",
    "        pos = pos - pos.iloc[0]\n",
    "        ln, = ax.plot(relativeTimes*1000, pos.values, c=colours[wm['type'][i]], label=wm['type'][i])\n",
    "        ret[wm['type'][i]].append(ln)\n",
    "    ax.set_xlim([0, 10000])\n",
    "    ax.set_ylim([-7, 7])\n",
    "    # Hide the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    # Set bounds of axes lines\n",
    "    #ax.spines['left'].set_bounds(0, 1)\n",
    "    #ax.spines['bottom'].set_bounds(1, len(dfs)+1)\n",
    "    # Explode out axes\n",
    "    ax.spines['left'].set_position(('outward',10))\n",
    "    ax.spines['bottom'].set_position(('outward',10))\n",
    "    ax.set_xlabel('Time from movement onset (ms)')\n",
    "    ax.set_ylabel('Relative position (cm)')\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moves at stim on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wheel, wm = load_wheel(refs[1][-2], rootDir=path)\n",
    "trials = alf.load_behavior(refs[1][-2], rootDir=path)\n",
    "print(list(trials.columns.values))\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "for i in range(0,len(trials)):\n",
    "    t = (wheel['times'] > trials['stimOn_times'][i]-1) & (wheel['times'] < trials['response_times'][i])\n",
    "    pos = wheel['position'][t]\n",
    "    wheelTimes = wheel['times'][t]\n",
    "    relativeTimes = wheelTimes - wheelTimes.iloc[0]\n",
    "    pos = pos - pos.iloc[0]\n",
    "    if len(pos) > 1000*60:\n",
    "        print(trials['stimOn_times'][i])\n",
    "        print(trials['response_times'][i])\n",
    "        continue\n",
    "    #if trials['choice'][i] == 1:\n",
    "    #    c = 'g-'\n",
    "    #elif trials['choice'][i] == -1:\n",
    "    #    c = 'r-'\n",
    "    #else:\n",
    "    #    c = 'k-'\n",
    "    if trials['feedbackType'][i] == 1:\n",
    "        c = 'g-'\n",
    "    elif trials['feedbackType'][i] == -1:\n",
    "        c = 'r-'\n",
    "    else:\n",
    "        c = 'k-'\n",
    "\n",
    "    ax.plot(relativeTimes*1000, pos, c)\n",
    "    ax.set_xlim([-10, 1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine if a mouse has learned the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def is_learned(dfs, verbose=False, returnIndex=False):\n",
    "    \"\"\"\n",
    "    Determine whether the mouse has met the criteria for having learned\n",
    "    \n",
    "    Example:\n",
    "        \n",
    "    Args: \n",
    "        dfs (list): List of data frames constructed from an ALF trials object.\n",
    "        verbose (bool): If True, prints the list of conditions that were(n't) met.\n",
    "        returnIndex: If True, returns the index of session on which mouse first \n",
    "                    met the 'learned' criteria.  This can take longer to process.\n",
    "        \n",
    "    Returns:\n",
    "        learned (bool or int): if returnIndex is True, returns a bool indicating \n",
    "                if the mouse has met the criteria, otherwise returns the index \n",
    "                of the session on which the mouse was first met those criteria.\n",
    "        \n",
    "    TODO: Should this take a mouse name as input instead?\n",
    "    TODO: Create conditions list, print list at end of function\n",
    "    \"\"\"\n",
    "    criteria = ['asymmetric trials already introduced',\n",
    "               'full contrast set introduced',\n",
    "               'over 300 trials on three consecutive sessions',\n",
    "               'performance at high contrast over 80% on three consecutive sessions'\n",
    "               'absolute bias below 16',\n",
    "               'threshold below 19',\n",
    "               'lapse rate below 20%']\n",
    "    learned = False\n",
    "    j = 0\n",
    "    for i in range(0,len(dfs),-1):\n",
    "        # If trial side prob uneven, the subject must have learned\n",
    "        if any(dfs[i]['probabilityLeft']!=0.5):\n",
    "            if not returnIndex:\n",
    "                learned = True\n",
    "                if verbose == True:\n",
    "                    print('Asymmetric trials already introduced')\n",
    "                break\n",
    "        # If there are fewer than 4 contrasts, subject can't have learned\n",
    "        elif len(dfs[i]['contrast'].unique()) < 4:\n",
    "            if verbose == True:\n",
    "                print('Low contrasts not yet introduced')\n",
    "            if returnIndex:\n",
    "                learned = None\n",
    "            break\n",
    "        else:\n",
    "            perfOnEasy = (sum(dfs[i]['feedbackType']==1. & abs(dfs[i]['contrast']) > .25)/\n",
    "                          sum(abs(dfs[i]['contrast'])))\n",
    "            if len(dfs[i]) > 200 & perfOnEasy > .8:\n",
    "                if j < 2:\n",
    "                    j += 1\n",
    "                else: # All three sessions meet criteria\n",
    "                    df = pd.concat(dfs[i:i+3])\n",
    "                    contrastSet = np.sort(df['contrast'].unique())\n",
    "                    nn = np.array([sum((df['contrast']==c) & (df['included']==True)) for c in contrastSet])\n",
    "                    pp = np.array([sum((df['contrast']==c) & (df['included']==True) & (df['choice']==-1.)) for c in contrastSet])/nn\n",
    "                    pars, L = psy.mle_fit_psycho(np.vstack((contrastSet,nn,pp)), \n",
    "                                     P_model='erf_psycho',\n",
    "                                     parstart=np.array([np.mean(contrastSet), 3., 0.05]),\n",
    "                                     parmin=np.array([np.min(contrastSet), 10., 0.]), \n",
    "                                     parmax=np.array([np.max(contrastSet), 30., .4]))\n",
    "                    if abs(pars[0]) > 16:\n",
    "                        if verbose == True:\n",
    "                            print('Absolute bias too high')\n",
    "                            break\n",
    "                    if pars[1] > 19:\n",
    "                        if verbose == True:\n",
    "                            print('Threshold too high')\n",
    "                            break\n",
    "                    if pars[2] > .2:\n",
    "                        if verbose == True:\n",
    "                            print('Lapse rate too high')\n",
    "                            break\n",
    "                    if verbose == True:\n",
    "                        print('Mouse learned')\n",
    "                    learned = True\n",
    "            else:\n",
    "                if verbose == True:\n",
    "                    print('Low trial count or performance at high contrast')\n",
    "                break\n",
    "                \n",
    "    if returnIndex & (not learned):\n",
    "        return None\n",
    "    elif returnIndex & learned:\n",
    "        return i + 3\n",
    "    else:\n",
    "        return learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(is_learned(dfs, verbose=True, returnIndex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at trial side manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Change plot_psychometric to split by side prob\n",
    "def plot_choice_by_side(df, ax=None):\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "    ax.scatter(df['contrast'][df['choice']==1], \n",
    "                df.index.values[df['choice']==1]+1, \n",
    "                s=100, marker='_', c='r')\n",
    "    ax.scatter(df['contrast'][df['choice']==-1], \n",
    "                df.index.values[df['choice']==-1]+1, \n",
    "                s=100, marker='_', c='b')\n",
    "def plot_choice_windowed(df, window=10, ax=None):\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "    # May require raw=False arg in older versions\n",
    "    pctRight = df['choice'].rolling(window).apply(lambda x: sum(x==1)/len(x))\n",
    "    ax.plot(pctRight, df.index.values+1)\n",
    "    ax.plot((.5,.5), (1,len(df)), 'k--')\n",
    "    ax.set_xlim([0,1.])\n",
    "    \n",
    "plot_choice_windowed(dfs[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting weight information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webclient import AlyxClient\n",
    "import datetime\n",
    "#baseURL = https://alyx.internationalbrainlab.org/\n",
    "baseURL = 'https://alyx.cortexlab.net/'\n",
    "ai = AlyxClient(username='miles', password=pwd, base_url=baseURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_records(subjects, ai):\n",
    "    s = ai.get('subjects?stock=False')\n",
    "    rmKeys = ['actions_sessions','water_administrations','weighings','genotype']\n",
    "    subject_info = []\n",
    "    records = []\n",
    "    weight_info = []\n",
    "    for s in subjects:\n",
    "        subj = ai.get('subjects/{}'.format(s))\n",
    "        subject_info.append({key: subj[key] for key in subj if key not in rmKeys})\n",
    "        endpoint = ('water-requirement/{}?start_date=2016-01-01&end_date={}'\n",
    "                    .format(s, datetime.datetime.now().strftime('%Y-%m-%d')))\n",
    "        wr = ai.get(endpoint)\n",
    "        if wr['implant_weight']:\n",
    "            iw = wr['implant_weight']\n",
    "        else:\n",
    "            iw = 0\n",
    "        #TODO MultiIndex without None\n",
    "        if not wr['records']:\n",
    "            records.append(None)\n",
    "        else:\n",
    "            df = pd.DataFrame(wr['records'])\n",
    "            df = (df.set_index(pd.DatetimeIndex(df['date']))\n",
    "                  .drop('date', axis=1)\n",
    "                  .assign(pct_weight = lambda x: \n",
    "                          (x['weight_measured']-iw) /\n",
    "                          (x['weight_expected']-iw) \n",
    "                          if 'weight_measured' in x.columns.values \n",
    "                          else np.nan))\n",
    "            records.append(df)\n",
    "            wr.pop('records', None)\n",
    "        weight_info.append(wr)\n",
    "\n",
    "    \n",
    "    info = (pd.DataFrame(weight_info)\n",
    "            .merge(pd.DataFrame(subject_info), left_on='subject', right_on='nickname')\n",
    "           .set_index('subject'))\n",
    "    records = pd.concat(records, keys=subjects, names=['name', 'date'])\n",
    "    return records, info\n",
    "records, info = get_weight_records(subjects, ai)\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_session_pct_weight(dfs, ax=None):\n",
    "    #TODO: Index lookup rather than rely on order\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "    idx = pd.IndexSlice\n",
    "    weightPCT = []\n",
    "    numTrials = []\n",
    "    for i,s in enumerate(records.index.get_level_values('name').unique()): \n",
    "        df = dfs[i]\n",
    "        expRef = [block.name for block in df]\n",
    "        date = [dat.parse_ref(ref)[1] for ref in expRef]\n",
    "        numTrials.append([len(block) for block in df if dat.parse_ref(df.name)[1] is in records.loc[idx[s, :]])\n",
    "        weightPCT.append(records.loc[idx[s, :], 'pct_weight'].values)\n",
    "    #ax.plot(np.array(numTrials),np.array(weightPCT))\n",
    "    return np.array(numTrials),np.array(weightPCT)\n",
    "n, w = plot_session_pct_weight(dfs)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s='ALK081'\n",
    "print(records.index.get_level_values('name').unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting weight information for all mice\n",
    "TODO: Package into function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webclient import AlyxClient\n",
    "import datetime\n",
    "#baseURL = https://alyx.internationalbrainlab.org/\n",
    "baseURL = 'https://alyx.cortexlab.net/'\n",
    "ai = AlyxClient(username='miles', password=pwd, base_url=baseURL)\n",
    "\n",
    "s = ai.get('subjects?stock=False')\n",
    "rmKeys = ['actions_sessions','water_administrations','weighings','genotype']\n",
    "subject_info = [{key: subj[key] for key in subj if key not in rmKeys} for subj in s]\n",
    "subject_info = pd.DataFrame(subject_info).set_index('nickname')\n",
    "records = []\n",
    "weight_info = []\n",
    "for s in subject_info.index.values:\n",
    "    endpoint = ('water-requirement/{}?start_date=2016-01-01&end_date={}'\n",
    "                .format(s, datetime.datetime.now().strftime('%Y-%m-%d')))\n",
    "    wr = ai.get(endpoint)\n",
    "    if wr['implant_weight']:\n",
    "        iw = wr['implant_weight']\n",
    "    else:\n",
    "        iw = 0\n",
    "    #TODO MultiIndex without None\n",
    "    if not wr['records']:\n",
    "        records.append(None)\n",
    "    else:\n",
    "        df = pd.DataFrame(wr['records'])\n",
    "        df = (df.set_index(pd.DatetimeIndex(df['date']))\n",
    "              .drop('date', axis=1)\n",
    "              .assign(pct_weight = lambda x: \n",
    "                      (x['weight_measured']-iw) /\n",
    "                      (x['weight_expected']-iw) \n",
    "                      if 'weight_measured' in x.columns.values \n",
    "                      else np.nan))\n",
    "        records.append(df)\n",
    "        wr.pop('records', None)\n",
    "    weight_info.append(wr)\n",
    "\n",
    "info = (pd.DataFrame(weight_info)\n",
    "        .merge(subject_info, left_on='subject', right_index=True)\n",
    "       .set_index('subject'))\n",
    "records = pd.concat(records, keys=subject_info.index.values, names=['name', 'date'])\n",
    "\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.to_pickle('info.pkl')\n",
    "records.to_pickle('records.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_pickle('info.pkl')\n",
    "records = pd.read_pickle('records.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting meta-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weight(records, ax=None):\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "    idx = pd.IndexSlice\n",
    "    for s in records.index.get_level_values('name'): \n",
    "        gt80 = ((records.loc[idx[s, :], 'pct_weight'] > 0.8) | \n",
    "                (records.loc[idx[s, :], 'pct_weight'].isnull()))\n",
    "        gt70 = ((records.loc[idx[s, :], 'pct_weight'] < 0.8) & \n",
    "                (records.loc[idx[s, :], 'pct_weight'] > 0.7) | \n",
    "                (records.loc[idx[s, :], 'pct_weight'].isnull()))\n",
    "        lt70 = ((records.loc[idx[s, :], 'pct_weight'] < 0.7) | \n",
    "                (records.loc[idx[s, :], 'pct_weight'].isnull()))\n",
    "        wtrDays = records.loc[idx[s, :], :].index.get_level_values(1)\n",
    "        wtrDays = wtrDays-wtrDays[0]\n",
    "        ax.plot(wtrDays[gt80], records.loc[idx[s, :], 'pct_weight'][gt80], 'k-')\n",
    "        ax.plot(wtrDays[gt70], records.loc[idx[s, :], 'pct_weight'][gt70], 'y-')\n",
    "        ax.plot(wtrDays[lt70], records.loc[idx[s, :], 'pct_weight'][lt70], 'r-')\n",
    "    return ax\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "plot_weight(records, ax)\n",
    "ax.set_ylim([0.7,1.25])\n",
    "ax.set_xlim([0,25e14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import AnchoredText\n",
    "def mean_weight_change(records):\n",
    "    idx = pd.IndexSlice\n",
    "    for s in records.index.get_level_values('name'):    \n",
    "        gt70 = (records.loc[idx[s, :], 'pct_weight'] > 0.7)\n",
    "        wtrDays = records.loc[idx[s, :], :].index.get_level_values(1)\n",
    "        records.loc[idx[s, :], 'days_from_start'] = wtrDays - wtrDays[0]\n",
    "        #ls.append(records.loc[idx[s, :], 'pct_weight'][gt70].values)\n",
    "mean_weight_change(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = (records.reset_index()\n",
    "           .set_index(['name', 'days_from_start'])\n",
    "           .replace([np.inf, -np.inf], np.nan))\n",
    "records['pct_weight'] = records['pct_weight'].where(records['pct_weight']>0.6)\n",
    "r = records.groupby(level=1,axis=0)['pct_weight'].describe()[['mean','std']]\n",
    "r['std'] = r['std'].where(r['std']<.5)\n",
    "r.plot(yerr='std', fmt='k-o')\n",
    "#plt.figure()\n",
    "ax = plt.gca()\n",
    "#ax.errorbar(r.index.days, r['mean'], yerr=r['std'])\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "# Set bounds of axes lines\n",
    "ax.spines['left'].set_bounds(.8, 1.1)\n",
    "ax.spines['bottom'].set_bounds(0, 14)\n",
    "# Explode out axes\n",
    "ax.spines['left'].set_position(('outward',10))\n",
    "ax.spines['bottom'].set_position(('outward',10))\n",
    "# Specify tick label size\n",
    "ax.tick_params(axis = 'y', which = 'major')\n",
    "ax.tick_params(axis = 'y', which = 'minor', labelsize = 0)\n",
    "# Suppress minor tick labels\n",
    "ax.set_yticks(np.arange(.8,1.11,.1))\n",
    "ax.set_yticks(np.arange(.8,1.11,.05), minor = True)\n",
    "ax.set_xticks(np.arange(0,101,7))\n",
    "ax.set_xticklabels(np.arange(0,101,7))\n",
    "#ax.set_xticks(np.arange(.8,1.11,.05), minor = True)\n",
    "ax.set_xlim([-.2,21])\n",
    "ax.set_ylim([.8,1.1])\n",
    "ax.legend().set_visible(False)\n",
    "ax.set_title('Mean percentage weight from first water restriction')\n",
    "anchored_text = AnchoredText('n = 90', loc=1, frameon=False)\n",
    "ax.add_artist(anchored_text)\n",
    "plt.xlabel('Days since water restriction')\n",
    "plt.ylabel('z-scored weight percent of initial weight')\n",
    "\n",
    "slider = widgets.IntRangeSlider(\n",
    "    value=(-1, 21),\n",
    "    min=-1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='x limit:',\n",
    "    disabled=False,\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    ")\n",
    "@interact(lim=slider)\n",
    "def set_xlim(lim):\n",
    "    lim = list(lim)\n",
    "    if lim[0]==-1:\n",
    "        lim[0] = -.2\n",
    "    ax.set_xlim(lim)\n",
    "    #an.annotate('n = 190', xy=(18, 1.05), xytext=(lim[1], 1.05))\n",
    "    ax.spines['bottom'].set_bounds(*lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx = pd.IndexSlice\n",
    "#records = (records.reset_index()\n",
    "#           .set_index(['name', 'date'])\n",
    "#           .replace([np.inf, -np.inf], np.nan))\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "for s in records.index.get_level_values('name'): \n",
    "    #ax.plot(records.sort_index(level=0).loc[idx[s, '2018-06-08':'2018-09-01'], 'weight_measured'])\n",
    "    rec = records.sort_index(level=0).loc[s,:,:].reset_index(['name'])\n",
    "    ax.plot(records.loc['2018-06-08':'2018-09-01', 'weight_measured'])\n",
    "    print(rec)\n",
    "    #ax.plot(records.loc[(s, '2018-06-08'):(s, '2018-09-01'),'weight_measured'])\n",
    "    \n",
    "ax.plot([datetime('2018-06-09'), datetime('2018-06-09')], [0,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('\\\\zserver.cortexlab.net\\Lab\\Share\\Miles\\behaviour\\subjectData.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_alf(fileName):\n",
    "    \"\"\"\n",
    "    Returns a True for a given file name if it is an ALF file, otherwise \n",
    "    returns False\n",
    "    \n",
    "    Examples:\n",
    "        match = is_alf('trials.feedbackType.npy')\n",
    "        match == True\n",
    "        >> True\n",
    "        match = is_alf('config.txt')\n",
    "        match == False\n",
    "        >> True\n",
    "    \n",
    "    Args:\n",
    "        fileName (str): The name of the file\n",
    "        \n",
    "    Returns:\n",
    "        bool\n",
    "    \n",
    "    @author: Miles\n",
    "    \"\"\"\n",
    "    pattern = r'(?P<nsp>_.+_)?(?P<obj>.+)\\.(?P<typ>.+)\\.(?P<ext>.+)'\n",
    "    out = re.match(pattern, fileName)\n",
    "    return out is not None\n",
    "def alf_parts(fileName):\n",
    "    \"\"\"\n",
    "    Return the object, type and extention for a given ALF file name\n",
    "    \n",
    "    Examples:\n",
    "        obj, typ, ext = alf_parts('trials.choice.npy')\n",
    "        (None, 'trials', 'choice', 'npy')\n",
    "        obj, typ, ext = alf_parts('_misc_trials.choice.npy')\n",
    "        ('_misc_', 'trials', 'choice', 'npy')\n",
    "    \n",
    "    Args:\n",
    "        fileName (str): The name of the file\n",
    "        \n",
    "    Returns:\n",
    "        nsp (str): The namespace, if present\n",
    "        obj (str): ALF object\n",
    "        typ (str): The ALF attribute\n",
    "        ext (str): The file extension\n",
    "        \n",
    "    TODO: Deal with namespaces\n",
    "    \n",
    "    @author: Miles\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pattern = r'(?P<nsp>_.+_)?(?P<obj>.+)\\.(?P<typ>.+)\\.(?P<ext>.+)'\n",
    "        out = re.match(pattern, fileName)\n",
    "    except:\n",
    "        print(fileName)\n",
    "    return out.groupdict()\n",
    "alf_parts('trials.feedbackType.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
